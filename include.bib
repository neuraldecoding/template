@article{AlRadhi2026Prompting,
author = {Al-Radhi, Mohammed Salah and Shurid, Sadi Mahmud and Németh, Géza},
title = {Prompting the Mind: EEG-to-Text Translation with Multimodal LLMs and Semantic Control},
year = {2026},
journal = {Lecture Notes in Computer Science},
volume = {16187 LNCS},
pages = {52 - 66},
doi = {10.1007/978-3-032-07956-5_4},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020236218&doi=10.1007%2F978-3-032-07956-5_4&partnerID=40&md5=c23d3435ce95bc801c6b7c0131dbcf8d},
affiliations = {},
abstract = {We present Prompting the Mind (PTM), an extended EEG-to-text translation framework that combines large language models (LLMs) with multimodal alignment to decode human brain signals into natural language. Our system follows a multi-stage pipeline: an EEG encoder first transforms raw neural activity into discriminative embeddings; these are then mapped into a shared vision-language semantic space using CLIP-based cross-modal alignment. Finally, a general-purpose base LLM, DeepSeek-7B-Base, generates descriptive text conditioned on the EEG-derived representations through structured prompting. We evaluate the framework on a publicly available EEG-image dataset, comparing its performance with chance-level and alignment-only baselines as well as an instruction-tuned LLM (Mistral-7B). Results on BLEU, METEOR, ROUGE-L, and BERTScore show that while instruction-tuned models yield higher token overlap, our prompt-conditioned base LLM produces shorter, more semantically faithful outputs that better align with the original brain signals. Qualitative examples highlight this trade-off and the practical value of structured prompting for non-invasive neural decoding. All code, prompt templates, and configuration files are shared (https://github.com/Sadi-Mahmud-Shurid/PTM) to promote reproducibility and future extensions of open-weight frameworks for brain-to-text communication. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.}, keywords = {Alignment; Biomedical signal processing; Brain; Brain computer interface; Computational linguistics; Electroencephalography; Interactive computer systems; Interfaces (computer); Natural language processing systems; Neural networks; Semantics; Signal encoding; Speech communication; Brain signals; EEG-to-text; Human brain; Language model; Language semantics; Large language model; Multi-modal; Multimodal alignment; Neural speech decoding; Speech decoding; Economic and social effects},
correspondence_address = {M.S. Al-Radhi; Department of Telecommunications and Artificial Intelligence, Budapest, Hungary; email: malradhi@tmit.bme.hu},
editor = {Karpov, A. and Gosztolya, G.},
publisher = {Springer Science and Business Media Deutschland GmbH},
issn = {16113349; 03029743},
isbn = {9789819698936; 9789819698042; 9789819698110; 9789819698905; 9783032004949; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141},
language = {English},
abbrev_source_title = {Lect. Notes Comput. Sci.},
type = {Conference paper}}
@article{Ban2026Advances,
author = {Ban, Seunghyeb and Chong, David and Kwon, Junwoo and Lee, Sangyoon and Huang, Yunuo and Yoo, Seungwon and Yeo, Woonhong},
title = {Advances in flexible high-density microelectrode arrays for brain-computer interfaces},
year = {2026},
journal = {Biosensors and Bioelectronics},
volume = {292},
pages = {},
doi = {10.1016/j.bios.2025.118102},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020972258&doi=10.1016%2Fj.bios.2025.118102&partnerID=40&md5=af95e495ea7a7478158942c611eec04f},
affiliations = {The George W. Woodruff School of Mechanical Engineering, Atlanta, GA, United States; Georgia Institute of Technology, Wearable Intelligent Systems and Healthcare Center (WISH Center), Atlanta, GA, United States; Cornell University College of Engineering, Ithaca, NY, United States; Pennsylvania State University, College of Engineering, University Park, PA, United States; Georgia Institute of Technology, School of Industrial Design, Atlanta, GA, United States; Wallace H. Coulter Department of Biomedical Engineering, Atlanta, GA, United States; Georgia Institute of Technology, Atlanta, GA, United States; Georgia Institute of Technology, Atlanta, GA, United States},
abstract = {Recent advances in flexible high-density microelectrode arrays (FHD-MEA) have revolutionized brain-computer interfaces (BCIs) by providing high spatial resolution, mechanical compliance, and long-term biocompatibility. This technology enables stable neural recording and precise stimulation, addressing the shortcomings of conventional rigid BCI arrays. In this review, we outline the challenges of signal acquisition and stimulation of conventional low-density, rigid BCI systems. These include poor spatial resolution, micro-motor-induced instability, electrochemical degradation, wiring bottlenecks, off-target activation, and charge injection hazards. We then describe how these barriers are addressed through advanced materials, device designs, and system-level integration. We summarize representative applications of clinical therapy for sensory enhancement, human-machine interfaces, and neurological diseases, highlighting translational potential. Collectively, this review article presents recent progress and emerging trends in establishing FHD-MEAs as a crucial foundation for next-generation, clinically viable BCIs. © 2025 The Authors.}, keywords = {Article; biocompatibility; brain mapping; decoding; degenerative disease; degradation; electric activity; electric potential; electrochemical degradation; electrocorticography; electroencephalogram; feature extraction; functional near-infrared spectroscopy; human; mechanical stress; nerve cell; neural decoding; neurologic disease; neurorehabilitation; somatosensory cortex; visual evoked potential; animal; brain; brain computer interface; devices; electroencephalography; equipment design; genetic procedures; microelectrode; physiology; procedures; Animals; Biosensing Techniques; Brain; Brain-Computer Interfaces; Electroencephalography; Equipment Design; Humans; Microelectrodes},
correspondence_address = {W.-H. Yeo; George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: whyeo@gatech.edu},
publisher = {Elsevier Ltd},
issn = {09565663; 18734235},
isbn = {9780128031018; 9780128031001},
coden = {BBIOE},
pmid = {41100980},
language = {English},
abbrev_source_title = {Biosens. Bioelectron.},
type = {Article}}
@article{Cao2026Eegclip,
author = {Cao, Xuhao and Gong, Peiliang and Zhang, Liying and Zhang, Daoqiang},
title = {EEG-CLIP: A transformer-based framework for EEG-guided image generation},
year = {2026},
journal = {Neural Networks},
volume = {194},
pages = {},
doi = {10.1016/j.neunet.2025.108167},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018169304&doi=10.1016%2Fj.neunet.2025.108167&partnerID=40&md5=e3591c868009a1ed98057f731f8e64c6},
affiliations = {Nanjing University of Aeronautics and Astronautics, MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing, Jiangsu, China},
abstract = {Decoding visual perception from neural signals represents a fundamental step toward advanced brain-computer interfaces (BCIs), where functional magnetic resonance imaging (fMRI) has shown promising results despite practical constraints in deployment and costs. Electroencephalography (EEG), with its superior temporal resolution, portability, and cost-effectiveness, emerges as a promising alternative for real-time brain-computer interface (BCI) applications. While existing EEG-based approaches have advanced neural decoding capabilities, they remain constrained by inadequate architectural designs, limited reconstruction fidelity, and inconsistent evaluation protocols. To address these challenges, we present EEG-CLIP, a novel Transformer-based framework that systematically addresses each limitation: (1) We introduce a specialized EEG-ViT encoder that adeptly captures the spatial and temporal characteristics of EEG signals to augment model capacity, along with a Diffusion Prior Transformer architecture to approximate the image feature distribution. (2) We employ a dual-stage reconstruction pipeline that integrates class contrastive learning and pretrained diffusion models to enhance visual reconstruction quality. (3) We establish comprehensive evaluation protocols across multiple datasets. Our framework operates through two stages: first projecting EEG signals into CLIP image space via class contrastive learning and refining them into image priors, then reconstructing perceived images through a pretrained conditional diffusion model. Comprehensive empirical analysis, including temporal window sensitivity studies and regional brain activation visualization, demonstrates the framework's robustness. We demonstrate through ablations that EEG-CLIP's performance improvements over previous methods result from specialized architecture for EEG encoding and improved training techniques. Quantitative and qualitative evaluations on ThingsEEG and Brain2Image datasets establish EEG-CLIP's state-of-the-art performance in both classification and reconstruction tasks, advancing neural signal-based visual decoding capabilities. © 2025 Elsevier Ltd}, keywords = {Activation analysis; Architecture; Biomedical signal processing; Brain; Brain computer interface; Brain mapping; Cost effectiveness; Decoding; Diffusion; Electrophysiology; Image coding; Image reconstruction; Interfaces (computer); Magnetic resonance imaging; Signal encoding; Brain decoding; Diffusion model; Evaluation protocol; Functional magnetic resonance imaging; Guided images; Image generations; Neural signals; Temporal resolution; Transformer; Visual perception; Electroencephalography; Article; brain analysis; brain region; computer model; cost effectiveness analysis; data visualization; diffusion; EEG CLIP; electroencephalogram; electroencephalography; functional magnetic resonance imaging; human; image analysis; image reconstruction; image segmentation; learning; mathematical analysis; neuroimaging; spatial analysis; supervised machine learning; temporal cortex; time series analysis; transformer based framework; visual stimulation},
correspondence_address = {P. Gong; MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; email: plgong@nuaa.edu.cn},
publisher = {Elsevier Ltd},
issn = {08936080; 18792782},
coden = {NNETE},
pmid = {41072287},
language = {English},
abbrev_source_title = {Neural Netw.},
type = {Article}}
@article{Ferrante2026Towards,
author = {Ferrante, Matteo and Boccato, Tommaso and Rashkov, Grigorii and Toschi, Nicola},
title = {Towards neural foundation models for vision: Aligning EEG, MEG, and fMRI representations for decoding, encoding, and modality conversion},
year = {2026},
journal = {Information Fusion},
volume = {126},
pages = {},
doi = {10.1016/j.inffus.2025.103650},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014517393&doi=10.1016%2Fj.inffus.2025.103650&partnerID=40&md5=3a85ce582045b38986515b01621d37c7},
affiliations = {Università degli Studi di Roma "Tor Vergata", Department of Biomedicine and Prevention, Rome, RM, Italy; Harvard Medical School, Boston, MA, United States},
abstract = {This paper presents a novel approach towards creating a foundational model for aligning neural data and visual stimuli across cross-modal representations of brain activity by leveraging contrastive learning. We leverage electroencephalography (EEG), magnetoencephalography (MEG), and functional magnetic resonance imaging (fMRI) data. The framework is validated through three key experiments: decoding visual information from neural data, encoding images into neural representations, and converting between neural modalities. The results highlight the model's ability to accurately capture semantic information across different brain imaging techniques, underscoring its potential in decoding, encoding, and modality conversion tasks. Our results reveal that EEG, MEG, and fMRI signals – despite being collected from different subjects and datasets – can be aligned in a shared vision-grounded space that preserves semantic information. This finding suggests the existence of modality-invariant neural codes and offers a new framework for comparing and decoding brain activity across heterogeneous non-invasive recordings. © 2025 The Authors}, keywords = {Biomedical signal processing; Brain; Brain mapping; Electroencephalography; Electrophysiology; Encoding (symbols); Image coding; Magnetic resonance imaging; Magnetoencephalography; Neural networks; Neurons; Semantics; Signal encoding; Brain activity; Brain decoding; Brain encoding; Encodings; Functional magnetic resonance imaging; Modality conversion; Neural data; Neural modality conversion; Neuroscience; Representation alignment; Vision},
correspondence_address = {M. Ferrante; University of Rome, Tor Vergata, Department of Biomedicine and Prevention, Rome, Italy; email: matteo.ferrante@uniroma2.it},
publisher = {Elsevier B.V.},
issn = {15662535; 18726305},
language = {English},
abbrev_source_title = {Inf. Fusion},
type = {Article}}
@article{Li2026Adaptive,
author = {Li, Pengrui and Peng, Maoqin and Zhang, Haokai and Liu, Shihong and Gao, Dongrui and Qin, Yun and Wu, Dingming and Liu, Tiejun},
title = {An adaptive decoupling learning system informed by the brain functional structure for EEG decoding},
year = {2026},
journal = {Neural Networks},
volume = {195},
pages = {},
doi = {10.1016/j.neunet.2025.108228},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019393504&doi=10.1016%2Fj.neunet.2025.108228&partnerID=40&md5=8cd0813aa6ebf02cb0b3dcf449612077},
affiliations = {University of Electronic Science and Technology of China, School of Life Science and Technology, Chengdu, Sichuan, China; Chengdu University of Information Technology, School of Computer Science, Chengdu, Sichuan, China},
abstract = {Neuroscientific investigations have revealed the presence of regional pathway connections among functional brain areas, as well as the asymmetrical structural characteristics of the left and right hemispheres. These connections, along with their potential coupling relationships and strengths, significantly influence the representation of neuronal signals as recorded by electroencephalography (EEG) within the cerebral cortex. Therefore, there is an urgent necessity to develop data-driven approaches that can effectively decode latent feature representations from EEG data. In this regard, the current study presents a functional-structural adaptive decoupling learning framework (FS-AD), which is informed by cognitive insights into the functional structure of the brain and integrates local-global spatial representations to decode EEG patterns across various states. To accomplish this, we initially implemented a one-dimensional separable convolution module and designed a local-domain attention interaction layer to extract inter-channel interaction information for each region, thereby enabling the capture of fully connected regional pathways. Following this, we developed a global-local kernel-level fusion decoder (GKFD) to amalgamate multiple local-domain features and decode them through a global-domain connection layer. Furthermore, a cross-domain adaptive fusion decoder (CAFD) was meticulously crafted to dynamically identify the fully connected optimal cross-domain pathway and decode it via a local-domain connection layer. The primary aim of FS-AD is to excavate the connectivity patterns of different brain states to enhance the efficiency of EEG decoding. The results indicate that the proposed FS-AD learning system significantly surpasses existing competitive methods in EEG decoding tasks related to various brain states, including fatigue, emotion, and motor imagery. Importantly, this study elucidates the variations in coupling strength among brain regional pathway connections and their representation of brain activity, while also investigating the optimal regional pathways under distinct brain states. This study contributes to the advancement of universal brain decoding methodologies. © 2025 Elsevier Ltd}, keywords = {Artificial intelligence; Biomedical signal processing; Brain; Decoding; Electrophysiology; Functional neuroimaging; Learning systems; Neurons; Adaptive decoupling; Brain decoding; Brain decoding technique; Brain state; Data-driven approach; Decoding techniques; Functional structure; Functionals; Learning frameworks; Regional pathway; Electroencephalography; Article; artificial intelligence; brain cortex; brain function; brain functional structure; brain region; cognition; convolutional neural network; electroencephalogram; electroencephalography; emotion; fatigue; graph neural network; hemisphere; human; independent component analysis; knowledge; learning; methodology; nerve cell network; power spectrum; short time Fourier transform},
correspondence_address = {D. Wu; School of Life Sciences and Technology, University of Electronic Science and Technology of China, Chengdu, 611731, China; email: dmw@uestc.edu.cn},
publisher = {Elsevier Ltd},
issn = {08936080; 18792782},
coden = {NNETE},
language = {English},
abbrev_source_title = {Neural Netw.},
type = {Article}}
@article{Sun2026Decoding,
author = {Sun, Kaili and Miao, Xingyu and Zhai, Bing and Duan, Haoran and Long, Yang},
title = {Decoding visual neural representations by multimodal with dynamic balancing},
year = {2026},
journal = {Expert Systems with Applications},
volume = {297},
pages = {},
doi = {10.1016/j.eswa.2025.129382},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013958067&doi=10.1016%2Fj.eswa.2025.129382&partnerID=40&md5=fb9e127a873b0ae5eb6e3ee3b1d536b0},
affiliations = {Durham University, Department of Computer Science, Durham, County Durham, United Kingdom; University of Northumbria, Department of Computer and Information Science, Newcastle, Tyne and Wear, United Kingdom; Tsinghua University, Department of Automation, Beijing, China},
abstract = {In this work, we propose an innovative framework that integrates EEG, image, and text data, aiming to decode visual neural representations from low signal-to-noise ratio EEG signals. Specifically, we introduce text modality to enhance the semantic correspondence between EEG signals and visual content. With the explicit semantic labels provided by text, image and EEG features of the same category can be more closely aligned with the corresponding text representations in a shared multimodal space. To fully utilize pre-trained visual and textual representations, we propose an adapter module that alleviates the instability of high-dimensional representation while facilitating the alignment and fusion of cross-modal features. Additionally, to alleviate the imbalance in multimodal feature contributions introduced by the textual representations, we propose a Modal Consistency Dynamic Balance (MCDB) strategy that dynamically adjusts the contribution weights of each modality. We further propose a stochastic perturbation regularization (SPR) term to enhance the generalization ability of semantic perturbation-based models by introducing dynamic Gaussian noise in the modality optimization process. The evaluation results on the ThingsEEG dataset show that our method surpasses previous state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by 2.0 % and 4.7 % respectively. © 2025 Elsevier Ltd}, keywords = {Balancing; Balancing machines; Biomedical signal processing; Brain; Dynamics; Electroencephalography; Gaussian noise (electronic); Neural networks; Semantics; Signal to noise ratio; Stochastic systems; Brain neural decoding; Dynamic balancing; EEG signals; Gradient modulation; Modal balance; Multi-modal; Multimodal contrastive learning; Neural decoding; Neural representations; Textual representation; Stochastic models},
correspondence_address = {Y. Long; Department of Computer Science, Durham University, United Kingdom; email: yang.long@durham.ac.uk},
publisher = {Elsevier Ltd},
issn = {09574174},
coden = {ESAPE},
language = {English},
abbrev_source_title = {Expert Sys Appl},
type = {Article}}
@article{Akama2025Predicting,
author = {Akama, Taketo and Zhang, Zhuohao and Li, Pengcheng and Hongo, Kotaro and Minamikawa, Shun and Polouliakh, Natalia},
title = {Predicting artificial neural network representations to learn recognition model for music identification from brain recordings},
year = {2025},
journal = {Scientific Reports},
volume = {15},
number = {1},
pages = {},
doi = {10.1038/s41598-025-02790-6},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006921300&doi=10.1038%2Fs41598-025-02790-6&partnerID=40&md5=0a09bfef60b913745aafc222ec92821e},
affiliations = {Sony Computer Science Laboratories, Inc., Tokyo, Japan},
abstract = {Recent studies have demonstrated that the representations of artificial neural networks (ANNs) can exhibit notable similarities to cortical representations when subjected to identical auditory sensory inputs. In these studies, the ability to predict cortical representations is probed by regressing from ANN representations to cortical representations. Building upon this concept, our approach reverses the direction of prediction: we utilize ANN representations as a supervisory signal to train recognition models using noisy brain recordings obtained through non-invasive measurements. Specifically, we focus on constructing a recognition model for music identification, where electroencephalography (EEG) brain recordings collected during music listening serve as input. By training an EEG recognition model to predict ANN representations-representations associated with music identification-we observed a significant improvement in classification accuracy. This study introduces a novel approach to developing recognition models for brain recordings in response to external auditory stimuli. It holds promise for advancing brain-computer interfaces (BCI), neural decoding techniques, and our understanding of music cognition. Furthermore, it provides new insights into the relationship between auditory brain activity and ANN representations. © The Author(s) 2025.},
keywords = {adult; artificial neural network; auditory stimulation; brain; brain computer interface; electroencephalography; female; hearing; human; male; music; physiology; young adult; Acoustic Stimulation; Adult; Auditory Perception; Brain; Brain-Computer Interfaces; Electroencephalography; Female; Humans; Male; Music; Neural Networks, Computer; Young Adult},
correspondence_address = {T. Akama; Sony Computer Science Laboratories, Inc, Tokyo, Japan; email: taketo.akama@sony.com},
publisher = {Nature Research},
issn = {20452322},
pmid = {40442206},
language = {English},
abbrev_source_title = {Sci. Rep.},
type = {Article}}
@article{Alcolea2025Less,
author = {Alcolea, Pedro I. and Ma, Xuan and Bodkin, Kevin L. and Miller, Lee E. and Danziger, Zachary C.},
title = {Less is more: selection from a small set of options improves BCI velocity control},
year = {2025},
journal = {Journal of Neural Engineering},
volume = {22},
number = {2},
pages = {},
doi = {10.1088/1741-2552/adbcd9},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000297308&doi=10.1088%2F1741-2552%2Fadbcd9&partnerID=40&md5=8ab5cd501432388330196d5593fbb0b0},
affiliations = {FIU College of Engineering and Computing, Miami, FL, United States; Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Robert R. McCormick School of Engineering and Applied Science, Evanston, IL, United States; Shirley Ryan AbilityLab, Chicago, IL, United States; Emory University School of Medicine, Division of Physical Therapy, Atlanta, GA, United States; Wallace H. Coulter Department of Biomedical Engineering, Atlanta, GA, United States},
abstract = {Objective. Decoding algorithms used in invasive brain-computer interfaces (iBCIs) typically convert neural activity into continuously varying velocity commands. We hypothesized that putting constraints on which decoded velocity commands are permissible could improve user performance. To test this hypothesis, we designed the discrete direction selection (DDS) decoder, which uses neural activity to select among a small menu of preset cursor velocities. Approach. We tested DDS in a closed-loop cursor control task against many common continuous velocity decoders in both a human-operated real-time iBCI simulator (the jaBCI) and in a monkey using an iBCI. In the jaBCI, we compared performance across four visits by each of 48 naïve, able-bodied human subjects using either DDS, direct regression with assist (an affine map from neural activity to cursor velocity, DR-A), ReFIT, or the velocity Kalman Filter (vKF). In a follow up study to verify the jaBCI results, we compared a monkey’s performance using an iBCI with either DDS or the Wiener filter decoder (a direct regression decoder that includes time history, WF). Main Result. In the jaBCI, DDS substantially outperformed all other decoders with 93% mean targets hit per visit compared to DR-A, ReFIT, and vKF with 56%, 39%, and 26% mean targets hit, respectively. With the iBCI, the monkey achieved a 61% success rate with DDS and a 37% success rate with WF. Significance. Discretizing the decoded velocity with DDS effectively traded high resolution velocity commands for less tortuous and lower noise trajectories, highlighting the potential benefits of discretization in simplifying online BCI control. © 2025 The Author(s). Published by IOP Publishing Ltd.}, keywords = {Brain mapping; Closed loop control systems; Kalman filters; Neurons; Wiener filtering; Center-out; Cursor control; Direction selection; Discrete velocity control; Interface modeling; Invasive brain-computer interface model (jaBCI); Monkey invasive brain-computer interface; Motor-cortex; Neural activity; Neural decoding; Brain computer interface; adult; affine transform; aged; animal experiment; Article; artificial neural network; cell activity; comparative study; controlled study; discretization; feedback system; finger joint; firing rate; follow up; Haplorhini; human; kalman filter; kinematics; measurement accuracy; motor cortex; nerve cell; noise; nonhuman; regression analysis; velocity; algorithm; animal; brain computer interface; electroencephalography; female; male; physiology; procedures; psychomotor performance; rhesus monkey; young adult; Adult; Algorithms; Animals; Brain-Computer Interfaces; Electroencephalography; Female; Humans; Macaca mulatta; Male; Psychomotor Performance; Young Adult},
correspondence_address = {Z.C. Danziger; Department of Biomedical Engineering, Florida International University, Miami, 33199, United States; email: zachary.danziger@emory.edu},
publisher = {Institute of Physics},
issn = {17412560},
coden = {JNEOB},
pmid = {40043320},
language = {English},
abbrev_source_title = {J. Neural Eng.},
type = {Article}}
@article{An2025Effects,
author = {An, Hyunjung and Lee, Jee-won and Park, Youngjin and Suh, Myung-Whan and Lim, Yoonseob},
title = {Effects of Age on the Neural Tracking of Speech in Noise},
year = {2025},
journal = {Brain Sciences},
volume = {15},
number = {8},
pages = {},
doi = {10.3390/brainsci15080874},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014466737&doi=10.3390%2Fbrainsci15080874&partnerID=40&md5=f0ef62ca91161f1c506739623f9d1e69},
affiliations = {Korea Institute of Science and Technology, Center for Intelligent and Interactive Robotics, Seoul, South Korea; Hallym University, Division of Speech Pathology and Audiology, Chuncheon, Gangwon-do, South Korea; Ewha Womans University, Department of Electrical and Electronic Engineering, Seoul, Seoul, South Korea; Korea Electrotechnology Research Institute, Electro-Medicine Device Research Division, Changwon, Gyeongsangnam-do, South Korea; Seoul National University Hospital, Department of Otolaryngology-Head and Neck Surgery, Seoul, South Korea; Hanyang University, Seoul, South Korea},
abstract = {Background: Older adults often struggle to comprehend speech in noisy environments, a challenge influenced by declines in both auditory processing and cognitive functions. This study aimed to investigate how differences in speech-in-noise perception among individual with clinically normal hearing thresholds (ranging from normal to mild hearing loss in older adults) are related to neural speech tracking and cognitive function, particularly working memory. Method: Specifically, we examined delta (1–4 Hz) and theta (4–8 Hz) EEG oscillations during speech recognition tasks to determine their association with cognitive performance in older adults. EEG data were collected from 23 young adults (20–35 years) and 23 older adults (65–80 years). Cognitive assessments were administered to older adults, and both groups completed an EEG task involving speech recognition in Speech-Shaped Noise (SSN) at individualized noise levels based on their Sentence Recognition Scores (SRS). Results: The results showed that age significantly impacted hit rates and reaction times in noisy speech recognition tasks. Theta-band neural tracking was notably stronger in older adults, while delta-band tracking showed no age-related difference. Pearson’s correlations indicated significant associations between age-related cognitive decline, reduced hearing sensitivity, and Mini-Mental State Examination (MMSE) scores. Regression analyses showed that theta-band neural tracking at specific SRS levels significantly predicted word list recognition in the higher SRT group, while constructional recall was strongly predicted in the lower SRT group. Conclusions: These findings suggest that older adults may rely on theta-band neural tracking as a compensatory mechanism. However, regression results alone were not sufficient to fully explain how working memory affects neural tracking, and additional cognitive and linguistic factors should be considered in future studies. Furthermore, cognitive assessments were administered only to older adults, which limits the ability to determine whether group differences are driven by age, hearing, or cognitive status—a major limitation that should be addressed in future research. © 2025 by the authors.}, keywords = {adult; aged; Article; auditory threshold; central nervous system function; cognition; cognitive defect; cognitive impairment assessment; dose response; electroencephalogram; electroencephalography; environmental noise; female; hearing; hearing acuity; hearing impairment; human; human experiment; male; mental performance; Mini Mental State Examination; neural decoding; Neural Tracking; noise; oscillation; reaction time; reliability; semantic memory; sensitivity and specificity; speech; speech discrimination; speech perception; Speech Recognition Score; Speech-Shaped Noise; verbal production; working memory},
correspondence_address = {Y. Lim; Center for Intelligent & Interactive Robotics, Korea Institute of Science and Technology, Seoul, 5, Hwarang-ro 14-gil, Seongbuk-gu, 02792, South Korea; email: yslim@kist.re.kr},
publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
issn = {20763425},
language = {English},
abbrev_source_title = {Brain Sci.},
type = {Article}}
@article{An2025Role,
author = {An, Hyunjung},
title = {The Role of Neurofeedback in Audiology: A Review of Current Evidence and Future Directions},
year = {2025},
journal = {Audiology and Speech Research},
volume = {21},
number = {3},
pages = {139 - 147},
doi = {10.21848/asr.250187},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012846841&doi=10.21848%2Fasr.250187&partnerID=40&md5=2c591f76045db696eedc9ce543b74fc3},
affiliations = {Hallym University, Division of Speech Pathology and Audiology, Chuncheon, Gangwon-do, South Korea},
abstract = {This study reviews the neurophysiological principles of neurofeedback (NFB) and its diverse clinical applications, with a particular focus on its emerging role in auditory rehabilitation and tinnitus treatment. By examining recent key studies, we explore how NFB extends beyond traditional psychological or behavioral modulation and offers potential for enhancing central auditory processing and cognitive regulation. Specifically, NFB has shown promise in modulating brain activity associated with auditory perception, attentional control, and neuroplasticity in both clinical and subclinical populations. Based on these findings, we propose future directions for sustained research on auditory-focused neurofeedback, emphasizing the need for individualized protocols, advanced neural decoding techniques, and integration with existing auditory assistive technologies. This review highlights NFB as a promising neurocognitive intervention within audiology and auditory neuroscience. © © 2025 Korean Academy of Audiology.},
keywords = {Auditory rehabilitation; Brain-computer interface (BCI); Electroencephalography (EEG); Neurofeedback (NF)},
correspondence_address = {H. An; Division of Speech Pathology and Audiology, Hallym University, Chuncheon, South Korea; email: hyunjung.an@hallym.ac.kr},
publisher = {Korean Academy of Audiology},
issn = {26355027; 26355019},
language = {Korean},
abbrev_source_title = {Audio. Speech Res.},
type = {Review}}
@inproceedings{Balasubramanian2025International,
author = {Balasubramanian, Arun and Pandey, Kartik and Veer, Gautam and Samanta, Debasis},
booktitle = {2025 13th International Conference on Brain-Computer Interface (BCI)},
title = {Activity Prediction for Localizing the Events in Imagined Speech EEG Signals},
year = {2025},
volume = {},
number = {},
pages = {1--5},
abstract = {Imagined speech electroencephalogram (EEG) signals are often collected for longer durations than necessary, leading to a difficulty in understanding the generation of EEG during the task as it is likely that most of the data collected is that of resting state. Developing a filter to identify the segments of the trials with actual information and remove those that contain the EEG from resting states could significantly advance our understanding of EEG signals in neuroscience and biomedical engineering. This work uses derivatives-based features to form the feature vectors used to train the classifiers. Based on feature importance analysis, it has been found that the derivative-based features contributed more to the classification than the traditionally preferred feature, band power in the alpha frequency band. Using the proposed features, the classification performance experienced a significant enhancement, surpassing the results reported in previous studies. The greater accuracy of the classifiers with the proposed features implies that they are effective at filtering out the resting state segments from imagined speech EEG signals.},
keywords = {Location awareness;Image segmentation;Accuracy;Neuroscience;Signal processing;Information filters;Feature extraction;Electroencephalography;Vectors;Speech processing;Imagined speech;EEG;resting state;signal processing;frequency analysis;feature importance;neural decoding},
doi = {10.1109/BCI65088.2025.10931413},
issn = {2572-7672},
month = {Feb}}